{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d103ffca-611c-4d16-88a4-9aecc4e153fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info_operations_clas already exists.\n"
     ]
    }
   ],
   "source": [
    "from currency_symbols import CurrencySymbols\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Define the regex patterns\n",
    "emoji_pattern = (\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    ")\n",
    "accented_characters = u\"\\u00C0-\\u00FF\"  # Latin-1 Supplement (accented characters)\n",
    "special_symbols = '©®™±≠≤≥∞π∑§¶†•′″‰′′←→↑↓↔↕'\n",
    "\n",
    "# ISO codes for all currencies \n",
    "currencies = [\n",
    "    'AFN', 'EUR', 'ALL', 'DZD', 'USD', 'EUR', 'AOA', 'XCD', 'XCD', 'ARS', 'AMD', 'AWG', 'AUD', 'EUR', 'AZN',\n",
    "    'BSD', 'BHD', 'BDT', 'BBD', 'BYN', 'EUR', 'BZD', 'XOF', 'BMD', 'INR', 'BTN', 'BOB', 'BOV', 'USD', 'BAM',\n",
    "    'BWP', 'NOK', 'BRL', 'USD', 'BND', 'BGN', 'XOF', 'BIF', 'CVE', 'KHR', 'XAF', 'CAD', 'KYD', 'XAF', 'XAF',\n",
    "    'CLP', 'CLF', 'CNY', 'AUD', 'AUD', 'COP', 'COU', 'KMF', 'CDF', 'XAF', 'NZD', 'CRC', 'XOF', 'EUR', 'CUP',\n",
    "    'CUC', 'ANG', 'EUR', 'CZK', 'DKK', 'DJF', 'XCD', 'DOP', 'USD', 'EGP', 'SVC', 'USD', 'XAF', 'ERN', 'EUR',\n",
    "    'SZL', 'ETB', 'EUR', 'FKP', 'DKK', 'FJD', 'EUR', 'EUR', 'EUR', 'XPF', 'EUR', 'XAF', 'GMD', 'GEL', 'EUR',\n",
    "    'GHS', 'GIP', 'EUR', 'DKK', 'XCD', 'EUR', 'USD', 'GTQ', 'GBP', 'GNF', 'XOF', 'GYD', 'HTG', 'USD', 'AUD',\n",
    "    'EUR', 'HNL', 'HKD', 'HUF', 'ISK', 'INR', 'IDR', 'XDR', 'IRR', 'IQD', 'EUR', 'GBP', 'ILS', 'EUR', 'JMD',\n",
    "    'JPY', 'GBP', 'JOD', 'KZT', 'KES', 'AUD', 'KPW', 'KRW', 'KWD', 'KGS', 'LAK', 'EUR', 'LBP', 'LSL', 'ZAR',\n",
    "    'LRD', 'LYD', 'CHF', 'EUR', 'EUR', 'MOP', 'MKD', 'MGA', 'MWK', 'MYR', 'MVR', 'XOF', 'EUR', 'USD', 'EUR',\n",
    "    'MRU', 'MUR', 'EUR', 'XUA', 'MXN', 'MXV', 'USD', 'MDL', 'EUR', 'MNT', 'EUR', 'XCD', 'MAD', 'MZN', 'MMK',\n",
    "    'NAD', 'ZAR', 'AUD', 'NPR', 'EUR', 'XPF', 'NZD', 'NIO', 'XOF', 'NGN', 'NZD', 'AUD', 'USD', 'NOK', 'OMR',\n",
    "    'PKR', 'USD', 'PAB', 'USD', 'PGK', 'PYG', 'PEN', 'PHP', 'NZD', 'PLN', 'EUR', 'USD', 'QAR', 'EUR', 'RON',\n",
    "    'RUB', 'RWF', 'EUR', 'SHP', 'XCD', 'XCD', 'EUR', 'EUR', 'XCD', 'WST', 'EUR', 'STN', 'SAR', 'XOF', 'RSD',\n",
    "    'SCR', 'SLE', 'SGD', 'ANG', 'XSU', 'EUR', 'EUR', 'SBD', 'SOS', 'ZAR', 'SSP', 'EUR', 'LKR', 'SDG', 'SRD',\n",
    "    'NOK', 'SEK', 'CHF', 'CHE', 'CHW', 'SYP', 'TWD', 'TJS', 'TZS', 'THB', 'USD', 'XOF', 'NZD', 'TOP', 'TTD',\n",
    "    'TND', 'TRY', 'TMT', 'USD', 'AUD', 'UGX', 'UAH', 'AED', 'GBP', 'USD', 'USD', 'USN', 'UYU', 'UYI', 'UYW',\n",
    "    'UZS', 'VUV', 'VES', 'VED', 'VND', 'USD', 'USD', 'XPF', 'MAD', 'YER', 'ZMW', 'ZWL', 'ZWG', 'XBA', 'XBB',\n",
    "    'XBC', 'XBD', 'XTS', 'XXX', 'XAU', 'XPD', 'XPT', 'XAG'\n",
    "]\n",
    "\n",
    "currency_symbols = [CurrencySymbols.get_symbol(x) for x in currencies]\n",
    "currency_symbols = [x for x in currency_symbols if x and not x.isalpha()]  # Filter out None values and alphabetic characters\n",
    "\n",
    "pattern_string = (\n",
    "    r'[^a-zA-Z0-9\\s' +\n",
    "    ''.join([re.escape(x) for x in string.punctuation]) +\n",
    "    ''.join([re.escape(x) for x in currency_symbols]) +\n",
    "    special_symbols +\n",
    "    emoji_pattern +\n",
    "    accented_characters +\n",
    "    ']'\n",
    ")\n",
    "\n",
    "pattern = re.compile(pattern_string, re.UNICODE)\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    #df_cleaned = df[~df.apply(lambda row: row.astype(str).str.contains(pattern).any(), axis=1)]\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace('\"', ' ')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.strip()\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.rstrip()\n",
    "    #escaped_chars_pattern = re.compile(r'[' + ''.join([re.escape(c) for c in ['\\\\', '\\t', '\\n']]) + ']')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(escaped_chars_pattern, ' ', regex=True)\n",
    "    #excessive_whitespace_pattern = re.compile(r'\\s{2,}')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(excessive_whitespace_pattern, ' ', regex=True)\n",
    "    #df_cleaned.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "    df_cleaned = df\n",
    "    # Convert BoW column from list to string\n",
    "    df_cleaned['BoW'] = df_cleaned['BoW'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "    ### later when i load this table as a df in google colab\n",
    "    ### Convert 'BoW' column to ndarray\n",
    "    ###df['BoW'] = df['BoW'].apply(lambda x: x.split())  # Split by space to get list of words\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def process_and_clean_csv(input_path):\n",
    "    df = pd.read_csv(input_path, header=0, index_col=False, sep=',', encoding='utf-8', on_bad_lines='skip')\n",
    "    df_cleaned = clean_dataframe(df)\n",
    "    return df_cleaned\n",
    "\n",
    "def load_to_bigquery(df, table_ref):\n",
    "    job = bigquery_client.load_table_from_dataframe(df, table_ref)\n",
    "    job.result()\n",
    "    print(f'Loaded DataFrame into {table_ref.table_id}.')\n",
    "\n",
    "# Service account key\n",
    "key_path = '/Users/chkapsalis/Downloads/nlp-project-427710-3e1a48df3dba.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Google Cloud project id and dataset information\n",
    "project_id = 'nlp-project-427710'\n",
    "dataset_id = 'info_operations_clas'  # Replace with your dataset ID\n",
    "table_id = 'all_tweets_hashed'  # Replace with your table ID\n",
    "\n",
    "# Initialization of the BigQuery client\n",
    "bigquery_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "\n",
    "# Create the dataset if it does not exist\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "\n",
    "try:\n",
    "    bigquery_client.get_dataset(dataset_ref)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} already exists.\")\n",
    "except:\n",
    "    dataset = bigquery_client.create_dataset(dataset)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} created.\")\n",
    "\n",
    "# Define the job configuration for loading data\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"userid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"user_reported_location\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"user_profile_description\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"follower_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"BoW\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"retweet_ratio\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"english_tweet_proportion\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"earliest_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"latest_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"average_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"median_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"tweet_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"stddev_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_0\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_1\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_2\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_3\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_4\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_5\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_6\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_7\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_8\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_9\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_10\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_11\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_12\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_13\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_14\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_15\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_16\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_17\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_18\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_19\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_20\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_21\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_22\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_23\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_week\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_day\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_hour\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_min\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_quote_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_like_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_retweet_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_hashtags\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_urls\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_user_mentions\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"info_op\", \"INTEGER\")\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    field_delimiter='|',  # used this custom delimiter to help make sense out of the data\n",
    "    autodetect=False,  # Automatically detect the schema\n",
    "    max_bad_records=2000,  # Allow up to 2000 bad records\n",
    "    ignore_unknown_values=True  # Ignore unknown values\n",
    ")\n",
    "\n",
    "source_folder = '/Users/chkapsalis/Downloads/info_operations_clas'\n",
    "filename = 'all_tweets_hashed.csv'\n",
    "source_file = os.path.join(source_folder, filename)\n",
    "df_cleaned = process_and_clean_csv(source_file)\n",
    "# making sure that the dtypes of columns match what asserted in the schema\n",
    "for col in df_cleaned.columns.difference(['userid','BoW']):\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "        \n",
    "# Upload the cleaned DataFrame to BigQuery\n",
    "#load_to_bigquery(df_cleaned, dataset_ref.table(table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486f59ed-61d1-4b8d-9033-c4e28c96ca45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22873094, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24740b56-1d02-49ab-9cd2-ebff63c2168b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info_op\n",
       "1    12023624\n",
       "0    10849470\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['info_op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cca0ad5-c701-4041-aa28-72250d3ac55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info_op\n",
      "1    1500000\n",
      "0    1500000\n",
      "Name: count, dtype: int64\n",
      "(3000000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Since we have that much data, we can randomly select a balanced sample \n",
    "# number of data points to keep from each category\n",
    "n_samples = 1500000\n",
    "\n",
    "# Select `n_samples` from each category\n",
    "df_sampled_1 = df_cleaned[df_cleaned['info_op'] == 1].sample(n=n_samples, random_state=1)\n",
    "df_sampled_0 = df_cleaned[df_cleaned['info_op'] == 0].sample(n=n_samples, random_state=1)\n",
    "\n",
    "# Combine the samples into a new DataFrame\n",
    "df_sampled = pd.concat([df_sampled_1, df_sampled_0])\n",
    "\n",
    "# sanity check\n",
    "print(df_sampled['info_op'].value_counts())\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(df_sampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212650a-87a2-43ef-8043-24cd947ac211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24f8c4-4d1f-4022-b10d-3477e9b5a71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f0428b-9ad6-4e1b-a015-9a69afb639c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if it has labels on both sides, upload... else examine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4663bf05-4d76-42e3-a08d-87f9603201b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame into all_tweets_hashed.\n"
     ]
    }
   ],
   "source": [
    "load_to_bigquery(df_sampled, dataset_ref.table(table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "673c447d-1c78-4b00-8468-13fcd8429904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetid', 'userid', 'tweet_time', 'is_retweet', 'quote_count',\n",
       "       'like_count', 'retweet_count', 'hashtags', 'urls', 'user_mentions',\n",
       "       'BoW', 'info_op'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5761e03-1db1-4391-a9b1-05c2fd199518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>BoW</th>\n",
       "      <th>info_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16267258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2b1e791d8e8d10517899e6cc3d054bf4a4245dff1f1167...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ ' l o c a l ' ,   ' b o d i e s ' ,   ' i n ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20803182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33c334fbf5f157f2428ea361a80b9ff2917b813dd09db0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15781546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17272bd5ecded41768a166c81ead83238de6481a64652e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18555705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9b6ede19a1a2ec1bf0a6914034f9baec6987979196654e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10865216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b67ec4ea371ad5854b702c48a6ea20b6c4345b5c1bbc4b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[ ' m a t e r i a l ' ,   ' l o o k ' ,   ' e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweetid                                             userid  \\\n",
       "16267258      NaN  2b1e791d8e8d10517899e6cc3d054bf4a4245dff1f1167...   \n",
       "20803182      NaN  33c334fbf5f157f2428ea361a80b9ff2917b813dd09db0...   \n",
       "15781546      NaN  17272bd5ecded41768a166c81ead83238de6481a64652e...   \n",
       "18555705      NaN  9b6ede19a1a2ec1bf0a6914034f9baec6987979196654e...   \n",
       "10865216      NaN  b67ec4ea371ad5854b702c48a6ea20b6c4345b5c1bbc4b...   \n",
       "\n",
       "          tweet_time  is_retweet  quote_count  like_count  retweet_count  \\\n",
       "16267258         NaN           0          0.0         0.0            0.0   \n",
       "20803182         NaN           0          0.0         0.0            0.0   \n",
       "15781546         NaN           1          0.0         0.0            0.0   \n",
       "18555705         NaN           0          0.0         0.0            0.0   \n",
       "10865216         NaN           0          0.0         0.0            0.0   \n",
       "\n",
       "          hashtags  urls  user_mentions  \\\n",
       "16267258         1     0              0   \n",
       "20803182         1     1              0   \n",
       "15781546         5     1              1   \n",
       "18555705         0     1              0   \n",
       "10865216         1     0              4   \n",
       "\n",
       "                                                        BoW  info_op  \n",
       "16267258  [ ' l o c a l ' ,   ' b o d i e s ' ,   ' i n ...        1  \n",
       "20803182                                                [ ]        1  \n",
       "15781546                                                [ ]        1  \n",
       "18555705                                                [ ]        1  \n",
       "10865216  [ ' m a t e r i a l ' ,   ' l o o k ' ,   ' e ...        1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60e0ef5-2ad4-4415-8789-23c29185ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3000000 entries, 16267258 to 8203036\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   tweetid        float64\n",
      " 1   userid         object \n",
      " 2   tweet_time     float64\n",
      " 3   is_retweet     int64  \n",
      " 4   quote_count    float64\n",
      " 5   like_count     float64\n",
      " 6   retweet_count  float64\n",
      " 7   hashtags       int64  \n",
      " 8   urls           int64  \n",
      " 9   user_mentions  int64  \n",
      " 10  BoW            object \n",
      " 11  info_op        int64  \n",
      "dtypes: float64(5), int64(5), object(2)\n",
      "memory usage: 297.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb42b4d-727c-4bb6-aac0-8828cf5cf5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
