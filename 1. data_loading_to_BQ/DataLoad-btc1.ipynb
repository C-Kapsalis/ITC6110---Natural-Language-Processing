{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71b80cc-10bd-4d03-8ad9-69e492a5d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chkapsalis/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset crypto already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 0/1 [00:00<?, ?it/s]/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:76: DtypeWarning: Columns (0,1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, header=0, index_col=False, encoding='utf-8', on_bad_lines='skip')\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text'] = df_cleaned['text'].str.replace('\"', ' ')\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text'] = df_cleaned['text'].str.strip()\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text'] = df_cleaned['text'].str.rstrip()\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text'] = df_cleaned['text'].str.replace(escaped_chars_pattern, ' ', regex=True)\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text'] = df_cleaned['text'].str.replace(excessive_whitespace_pattern, ' ', regex=True)\n",
      "/var/folders/fp/b19fbw2j41z9_lyxq1cyd88h0000gn/T/ipykernel_27260/433224081.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.drop(['date', 'hard_cleaned_text', 'soft_cleaned_text'], axis=1, inplace=True)\n",
      "  0%|                                                                             | 0/1 [1:47:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert '304.0' with type str: tried to convert to double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 146\u001b[0m\n\u001b[1;32m    143\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m process_and_clean_csv(source_file)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Upload the cleaned DataFrame to BigQuery\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[43mload_to_bigquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m, in \u001b[0;36mload_to_bigquery\u001b[0;34m(df, table_ref)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_to_bigquery\u001b[39m(df, table_ref):\n\u001b[0;32m---> 89\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     job\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded DataFrame into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_ref\u001b[38;5;241m.\u001b[39mtable_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/bigquery/client.py:2777\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[1;32m   2759\u001b[0m         columns_and_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[1;32m   2760\u001b[0m             name\n\u001b[1;32m   2761\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m _pandas_helpers\u001b[38;5;241m.\u001b[39mlist_columns_and_indexes(dataframe)\n\u001b[1;32m   2762\u001b[0m         )\n\u001b[1;32m   2763\u001b[0m         new_job_config\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2764\u001b[0m             \u001b[38;5;66;03m# Field description and policy tags are not needed to\u001b[39;00m\n\u001b[1;32m   2765\u001b[0m             \u001b[38;5;66;03m# serialize a data frame.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2774\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m columns_and_indexes\n\u001b[1;32m   2775\u001b[0m         ]\n\u001b[0;32m-> 2777\u001b[0m new_job_config\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_bq_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\n\u001b[1;32m   2779\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_job_config\u001b[38;5;241m.\u001b[39mschema:\n\u001b[1;32m   2782\u001b[0m     \u001b[38;5;66;03m# the schema could not be fully detected\u001b[39;00m\n\u001b[1;32m   2783\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchema could not be detected for all columns. Loading from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe without a schema will be deprecated in the future, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2788\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2789\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/bigquery/_pandas_helpers.py:500\u001b[0m, in \u001b[0;36mdataframe_to_bq_schema\u001b[0;34m(dataframe, bq_schema)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# We cannot detect the schema in full.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# The augment_schema() helper itself will also issue unknown type\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# warnings if detection still fails for any of the fields.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     bq_schema_out \u001b[38;5;241m=\u001b[39m \u001b[43maugment_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_schema_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(bq_schema_out) \u001b[38;5;28;01mif\u001b[39;00m bq_schema_out \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/google/cloud/bigquery/_pandas_helpers.py:529\u001b[0m, in \u001b[0;36maugment_schema\u001b[0;34m(dataframe, current_bq_schema)\u001b[0m\n\u001b[1;32m    526\u001b[0m     augmented_schema\u001b[38;5;241m.\u001b[39mappend(field)\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_list(arrow_table\u001b[38;5;241m.\u001b[39mtype):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# `pyarrow.ListType`\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     detected_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPEATED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not convert '304.0' with type str: tried to convert to double"
     ]
    }
   ],
   "source": [
    "from currency_symbols import CurrencySymbols\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Define the regex patterns\n",
    "emoji_pattern = (\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    ")\n",
    "accented_characters = u\"\\u00C0-\\u00FF\"  # Latin-1 Supplement (accented characters)\n",
    "special_symbols = '¬©¬Æ‚Ñ¢¬±‚â†‚â§‚â•‚àûœÄ‚àë¬ß¬∂‚Ä†‚Ä¢‚Ä≤‚Ä≥‚Ä∞‚Ä≤‚Ä≤‚Üê‚Üí‚Üë‚Üì‚Üî‚Üï'\n",
    "\n",
    "# ISO codes for all currencies \n",
    "currencies = [\n",
    "    'AFN', 'EUR', 'ALL', 'DZD', 'USD', 'EUR', 'AOA', 'XCD', 'XCD', 'ARS', 'AMD', 'AWG', 'AUD', 'EUR', 'AZN',\n",
    "    'BSD', 'BHD', 'BDT', 'BBD', 'BYN', 'EUR', 'BZD', 'XOF', 'BMD', 'INR', 'BTN', 'BOB', 'BOV', 'USD', 'BAM',\n",
    "    'BWP', 'NOK', 'BRL', 'USD', 'BND', 'BGN', 'XOF', 'BIF', 'CVE', 'KHR', 'XAF', 'CAD', 'KYD', 'XAF', 'XAF',\n",
    "    'CLP', 'CLF', 'CNY', 'AUD', 'AUD', 'COP', 'COU', 'KMF', 'CDF', 'XAF', 'NZD', 'CRC', 'XOF', 'EUR', 'CUP',\n",
    "    'CUC', 'ANG', 'EUR', 'CZK', 'DKK', 'DJF', 'XCD', 'DOP', 'USD', 'EGP', 'SVC', 'USD', 'XAF', 'ERN', 'EUR',\n",
    "    'SZL', 'ETB', 'EUR', 'FKP', 'DKK', 'FJD', 'EUR', 'EUR', 'EUR', 'XPF', 'EUR', 'XAF', 'GMD', 'GEL', 'EUR',\n",
    "    'GHS', 'GIP', 'EUR', 'DKK', 'XCD', 'EUR', 'USD', 'GTQ', 'GBP', 'GNF', 'XOF', 'GYD', 'HTG', 'USD', 'AUD',\n",
    "    'EUR', 'HNL', 'HKD', 'HUF', 'ISK', 'INR', 'IDR', 'XDR', 'IRR', 'IQD', 'EUR', 'GBP', 'ILS', 'EUR', 'JMD',\n",
    "    'JPY', 'GBP', 'JOD', 'KZT', 'KES', 'AUD', 'KPW', 'KRW', 'KWD', 'KGS', 'LAK', 'EUR', 'LBP', 'LSL', 'ZAR',\n",
    "    'LRD', 'LYD', 'CHF', 'EUR', 'EUR', 'MOP', 'MKD', 'MGA', 'MWK', 'MYR', 'MVR', 'XOF', 'EUR', 'USD', 'EUR',\n",
    "    'MRU', 'MUR', 'EUR', 'XUA', 'MXN', 'MXV', 'USD', 'MDL', 'EUR', 'MNT', 'EUR', 'XCD', 'MAD', 'MZN', 'MMK',\n",
    "    'NAD', 'ZAR', 'AUD', 'NPR', 'EUR', 'XPF', 'NZD', 'NIO', 'XOF', 'NGN', 'NZD', 'AUD', 'USD', 'NOK', 'OMR',\n",
    "    'PKR', 'USD', 'PAB', 'USD', 'PGK', 'PYG', 'PEN', 'PHP', 'NZD', 'PLN', 'EUR', 'USD', 'QAR', 'EUR', 'RON',\n",
    "    'RUB', 'RWF', 'EUR', 'SHP', 'XCD', 'XCD', 'EUR', 'EUR', 'XCD', 'WST', 'EUR', 'STN', 'SAR', 'XOF', 'RSD',\n",
    "    'SCR', 'SLE', 'SGD', 'ANG', 'XSU', 'EUR', 'EUR', 'SBD', 'SOS', 'ZAR', 'SSP', 'EUR', 'LKR', 'SDG', 'SRD',\n",
    "    'NOK', 'SEK', 'CHF', 'CHE', 'CHW', 'SYP', 'TWD', 'TJS', 'TZS', 'THB', 'USD', 'XOF', 'NZD', 'TOP', 'TTD',\n",
    "    'TND', 'TRY', 'TMT', 'USD', 'AUD', 'UGX', 'UAH', 'AED', 'GBP', 'USD', 'USD', 'USN', 'UYU', 'UYI', 'UYW',\n",
    "    'UZS', 'VUV', 'VES', 'VED', 'VND', 'USD', 'USD', 'XPF', 'MAD', 'YER', 'ZMW', 'ZWL', 'ZWG', 'XBA', 'XBB',\n",
    "    'XBC', 'XBD', 'XTS', 'XXX', 'XAU', 'XPD', 'XPT', 'XAG'\n",
    "]\n",
    "\n",
    "currency_symbols = [CurrencySymbols.get_symbol(x) for x in currencies]\n",
    "currency_symbols = [x for x in currency_symbols if x and not x.isalpha()]  # Filter out None values and alphabetic characters\n",
    "\n",
    "pattern_string = (\n",
    "    r'[^a-zA-Z0-9\\s' +\n",
    "    ''.join([re.escape(x) for x in string.punctuation]) +\n",
    "    ''.join([re.escape(x) for x in currency_symbols]) +\n",
    "    special_symbols +\n",
    "    emoji_pattern +\n",
    "    accented_characters +\n",
    "    ']'\n",
    ")\n",
    "\n",
    "pattern = re.compile(pattern_string, re.UNICODE)\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df_cleaned = df[~df.apply(lambda row: row.astype(str).str.contains(pattern).any(), axis=1)]\n",
    "    df_cleaned['text'] = df_cleaned['text'].str.replace('\"', ' ')\n",
    "    df_cleaned['text'] = df_cleaned['text'].str.strip()\n",
    "    df_cleaned['text'] = df_cleaned['text'].str.rstrip()\n",
    "    escaped_chars_pattern = re.compile(r'[' + ''.join([re.escape(c) for c in ['\\\\', '\\t', '\\n']]) + ']')\n",
    "    df_cleaned['text'] = df_cleaned['text'].str.replace(escaped_chars_pattern, ' ', regex=True)\n",
    "    excessive_whitespace_pattern = re.compile(r'\\s{2,}')\n",
    "    df_cleaned['text'] = df_cleaned['text'].str.replace(excessive_whitespace_pattern, ' ', regex=True)\n",
    "    df_cleaned.drop(['date', 'hard_cleaned_text', 'soft_cleaned_text'], axis=1, inplace=True)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def process_and_clean_csv(input_path):\n",
    "    df = pd.read_csv(input_path, header=0, index_col=False, encoding='utf-8', on_bad_lines='skip')\n",
    "    df_cleaned = clean_dataframe(df)\n",
    "    return df_cleaned\n",
    "\n",
    "def upload_file(bucket_name, source_file_path, destination_blob_name):\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    storage.blob._DEFAULT_CHUNKSIZE = 100 * 1024 * 1024  # 100 MB chunk size\n",
    "    storage.blob._MAX_MULTIPART_SIZE = 100 * 1024 * 1024  # 100 MB max multipart size\n",
    "    blob.upload_from_filename(source_file_path, timeout=600)\n",
    "    print(f'{source_file_path} uploaded to {bucket_name} as {destination_blob_name}.')\n",
    "\n",
    "def load_to_bigquery(df, table_ref):\n",
    "    job = bigquery_client.load_table_from_dataframe(df, table_ref)\n",
    "    job.result()\n",
    "    print(f'Loaded DataFrame into {table_ref.table_id}.')\n",
    "\n",
    "# Service account key\n",
    "key_path = '/Users/chkapsalis/Downloads/nlp-project-427710-3e1a48df3dba.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Google Cloud project id and dataset information\n",
    "project_id = 'nlp-project-427710'\n",
    "dataset_id = 'crypto'  # Replace with your dataset ID\n",
    "table_id = 'btc1'  # Replace with your table ID\n",
    "\n",
    "# Initialization of the BigQuery client\n",
    "bigquery_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "\n",
    "# Create the dataset if it does not exist\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "\n",
    "try:\n",
    "    bigquery_client.get_dataset(dataset_ref)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} already exists.\")\n",
    "except:\n",
    "    dataset = bigquery_client.create_dataset(dataset)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} created.\")\n",
    "\n",
    "# Define the job configuration for loading data\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"user_followers\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"user_verified\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"vader_sentiment\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"afinn_sentiment\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"sentiment\", \"DECIMAL\")\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    field_delimiter='|',  # used this custom delimiter to help make sense out of the data\n",
    "    autodetect=False,  # Automatically detect the schema\n",
    "    max_bad_records=2000,  # Allow up to 2000 bad records\n",
    "    ignore_unknown_values=True  # Ignore unknown values\n",
    ")\n",
    "\n",
    "source_folder = '/Users/chkapsalis/Downloads/btc1'\n",
    "cleaned_folder = '/Users/chkapsalis/Downloads/cleaned_btc1'\n",
    "\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(source_folder)):\n",
    "    if filename.endswith('.csv'):\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        df_cleaned = process_and_clean_csv(source_file)\n",
    "\n",
    "        # making sure that the dtypes of columns match what asserted in the schema\n",
    "        df_cleaned['user_followers'] = pd.to_numeric(df_cleaned['user_followers'], errors='coerce')\n",
    "\n",
    "        \n",
    "        # Upload the cleaned DataFrame to BigQuery\n",
    "        #load_to_bigquery(df_cleaned, dataset_ref.table(table_id))\n",
    "        load_to_bigquery(df_cleaned.iloc[:1000000, ], dataset_ref.table(table_id))\n",
    "        load_to_bigquery(df_cleaned.iloc[1000000:3000000, ], dataset_ref.table(table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8db890-6e98-4cdc-b75e-bc623dfcc8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>text</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>afinn_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625.0</td>\n",
       "      <td>0</td>\n",
       "      <td>$BTC A big chance in a billion! Price: 4872644...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.279487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;'fire' &amp;amp; 'man'&amp;gt; #Bitcoin #Crypto #B...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.097325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1159.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Annnd #btc #Bitcoin is headed even higher now....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>0.148718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>668.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#Bitcoin #BTC $BTC $GBTC $RIOT $MARA $ETH $ETH...</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>-0.094755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>‚¨ÜÔ∏è‚¨ÜÔ∏è $BTC BUYING PRESSURE ALERT üìà Price tradin...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843179</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#DogelonMars is the future. #TSUKA is the next...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.306767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843180</th>\n",
       "      <td>674.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bitcoin squeeze is SUPER TIGHT, which way will...</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.419247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843181</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Closed #BTC short at 16725. Missed my long pla...</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>-0.116755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843182</th>\n",
       "      <td>532.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#Ethereum price update: #ETH $1263.59 USD #Bit...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>0.148718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843184</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Earn crypto by playing fun games online. Get r...</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.595426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94009455 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_followers user_verified  \\\n",
       "3                 625.0             0   \n",
       "6                 131.0             0   \n",
       "10               1159.0             0   \n",
       "13                668.0             0   \n",
       "14               1281.0             0   \n",
       "...                 ...           ...   \n",
       "94843179           66.0             0   \n",
       "94843180          674.0             0   \n",
       "94843181           79.0             0   \n",
       "94843182          532.0             0   \n",
       "94843184           14.0             0   \n",
       "\n",
       "                                                       text  vader_sentiment  \\\n",
       "3         $BTC A big chance in a billion! Price: 4872644...           0.2500   \n",
       "6         &lt;'fire' &amp; 'man'&gt; #Bitcoin #Crypto #B...          -0.0772   \n",
       "10        Annnd #btc #Bitcoin is headed even higher now....           0.0000   \n",
       "13        #Bitcoin #BTC $BTC $GBTC $RIOT $MARA $ETH $ETH...          -0.5574   \n",
       "14        ‚¨ÜÔ∏è‚¨ÜÔ∏è $BTC BUYING PRESSURE ALERT üìà Price tradin...           0.0000   \n",
       "...                                                     ...              ...   \n",
       "94843179  #DogelonMars is the future. #TSUKA is the next...           0.3182   \n",
       "94843180  Bitcoin squeeze is SUPER TIGHT, which way will...           0.5994   \n",
       "94843181  Closed #BTC short at 16725. Missed my long pla...          -0.6124   \n",
       "94843182  #Ethereum price update: #ETH $1263.59 USD #Bit...           0.0000   \n",
       "94843184  Earn crypto by playing fun games online. Get r...           0.8860   \n",
       "\n",
       "          afinn_sentiment  sentiment  \n",
       "3                0.299145   0.279487  \n",
       "6                0.213675   0.097325  \n",
       "10               0.247863   0.148718  \n",
       "13               0.213675  -0.094755  \n",
       "14               0.213675   0.128205  \n",
       "...                   ...        ...  \n",
       "94843179         0.299145   0.306767  \n",
       "94843180         0.299145   0.419247  \n",
       "94843181         0.213675  -0.116755  \n",
       "94843182         0.247863   0.148718  \n",
       "94843184         0.401709   0.595426  \n",
       "\n",
       "[94009455 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9387c5-c9c3-4338-8c6b-f431f5a8438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94009455 entries, 3 to 94843184\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   user_followers   object \n",
      " 1   user_verified    object \n",
      " 2   text             object \n",
      " 3   vader_sentiment  float64\n",
      " 4   afinn_sentiment  float64\n",
      " 5   sentiment        float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 4.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d274e7f-38b2-4c8a-a429-11ec5fb73141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['user_followers'] = pd.to_numeric(df_cleaned['user_followers'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4e2c48-acd4-4216-9754-5fdaf956986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94009455 entries, 3 to 94843184\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   user_followers   float64\n",
      " 1   user_verified    object \n",
      " 2   text             object \n",
      " 3   vader_sentiment  float64\n",
      " 4   afinn_sentiment  float64\n",
      " 5   sentiment        float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 4.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bbd785-2811-45b6-8f43-4f12145413a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame into btc1.\n"
     ]
    }
   ],
   "source": [
    "load_to_bigquery(df_cleaned.iloc[:1000000, ], dataset_ref.table(table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04d57d8-615c-4185-8328-dbd44448570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame into btc1.\n"
     ]
    }
   ],
   "source": [
    "load_to_bigquery(df_cleaned.iloc[1000000:3000000, ], dataset_ref.table(table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3457a88-4138-4ad7-b3b7-4dd6aeef4d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
