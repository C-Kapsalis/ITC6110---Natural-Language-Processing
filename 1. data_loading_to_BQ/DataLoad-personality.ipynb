{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "575c8f26-90da-4934-ba39-98574181fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset person_emotion already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 2/2 [01:41<00:00, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame into MBTI_personality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from currency_symbols import CurrencySymbols\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Define the regex patterns\n",
    "emoji_pattern = (\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    ")\n",
    "accented_characters = u\"\\u00C0-\\u00FF\"  # Latin-1 Supplement (accented characters)\n",
    "special_symbols = '©®™±≠≤≥∞π∑§¶†•′″‰′′←→↑↓↔↕'\n",
    "\n",
    "# ISO codes for all currencies \n",
    "currencies = [\n",
    "    'AFN', 'EUR', 'ALL', 'DZD', 'USD', 'EUR', 'AOA', 'XCD', 'XCD', 'ARS', 'AMD', 'AWG', 'AUD', 'EUR', 'AZN',\n",
    "    'BSD', 'BHD', 'BDT', 'BBD', 'BYN', 'EUR', 'BZD', 'XOF', 'BMD', 'INR', 'BTN', 'BOB', 'BOV', 'USD', 'BAM',\n",
    "    'BWP', 'NOK', 'BRL', 'USD', 'BND', 'BGN', 'XOF', 'BIF', 'CVE', 'KHR', 'XAF', 'CAD', 'KYD', 'XAF', 'XAF',\n",
    "    'CLP', 'CLF', 'CNY', 'AUD', 'AUD', 'COP', 'COU', 'KMF', 'CDF', 'XAF', 'NZD', 'CRC', 'XOF', 'EUR', 'CUP',\n",
    "    'CUC', 'ANG', 'EUR', 'CZK', 'DKK', 'DJF', 'XCD', 'DOP', 'USD', 'EGP', 'SVC', 'USD', 'XAF', 'ERN', 'EUR',\n",
    "    'SZL', 'ETB', 'EUR', 'FKP', 'DKK', 'FJD', 'EUR', 'EUR', 'EUR', 'XPF', 'EUR', 'XAF', 'GMD', 'GEL', 'EUR',\n",
    "    'GHS', 'GIP', 'EUR', 'DKK', 'XCD', 'EUR', 'USD', 'GTQ', 'GBP', 'GNF', 'XOF', 'GYD', 'HTG', 'USD', 'AUD',\n",
    "    'EUR', 'HNL', 'HKD', 'HUF', 'ISK', 'INR', 'IDR', 'XDR', 'IRR', 'IQD', 'EUR', 'GBP', 'ILS', 'EUR', 'JMD',\n",
    "    'JPY', 'GBP', 'JOD', 'KZT', 'KES', 'AUD', 'KPW', 'KRW', 'KWD', 'KGS', 'LAK', 'EUR', 'LBP', 'LSL', 'ZAR',\n",
    "    'LRD', 'LYD', 'CHF', 'EUR', 'EUR', 'MOP', 'MKD', 'MGA', 'MWK', 'MYR', 'MVR', 'XOF', 'EUR', 'USD', 'EUR',\n",
    "    'MRU', 'MUR', 'EUR', 'XUA', 'MXN', 'MXV', 'USD', 'MDL', 'EUR', 'MNT', 'EUR', 'XCD', 'MAD', 'MZN', 'MMK',\n",
    "    'NAD', 'ZAR', 'AUD', 'NPR', 'EUR', 'XPF', 'NZD', 'NIO', 'XOF', 'NGN', 'NZD', 'AUD', 'USD', 'NOK', 'OMR',\n",
    "    'PKR', 'USD', 'PAB', 'USD', 'PGK', 'PYG', 'PEN', 'PHP', 'NZD', 'PLN', 'EUR', 'USD', 'QAR', 'EUR', 'RON',\n",
    "    'RUB', 'RWF', 'EUR', 'SHP', 'XCD', 'XCD', 'EUR', 'EUR', 'XCD', 'WST', 'EUR', 'STN', 'SAR', 'XOF', 'RSD',\n",
    "    'SCR', 'SLE', 'SGD', 'ANG', 'XSU', 'EUR', 'EUR', 'SBD', 'SOS', 'ZAR', 'SSP', 'EUR', 'LKR', 'SDG', 'SRD',\n",
    "    'NOK', 'SEK', 'CHF', 'CHE', 'CHW', 'SYP', 'TWD', 'TJS', 'TZS', 'THB', 'USD', 'XOF', 'NZD', 'TOP', 'TTD',\n",
    "    'TND', 'TRY', 'TMT', 'USD', 'AUD', 'UGX', 'UAH', 'AED', 'GBP', 'USD', 'USD', 'USN', 'UYU', 'UYI', 'UYW',\n",
    "    'UZS', 'VUV', 'VES', 'VED', 'VND', 'USD', 'USD', 'XPF', 'MAD', 'YER', 'ZMW', 'ZWL', 'ZWG', 'XBA', 'XBB',\n",
    "    'XBC', 'XBD', 'XTS', 'XXX', 'XAU', 'XPD', 'XPT', 'XAG'\n",
    "]\n",
    "\n",
    "currency_symbols = [CurrencySymbols.get_symbol(x) for x in currencies]\n",
    "currency_symbols = [x for x in currency_symbols if x and not x.isalpha()]  # Filter out None values and alphabetic characters\n",
    "\n",
    "pattern_string = (\n",
    "    r'[^a-zA-Z0-9\\s' +\n",
    "    ''.join([re.escape(x) for x in string.punctuation]) +\n",
    "    ''.join([re.escape(x) for x in currency_symbols]) +\n",
    "    special_symbols +\n",
    "    emoji_pattern +\n",
    "    accented_characters +\n",
    "    ']'\n",
    ")\n",
    "\n",
    "pattern = re.compile(pattern_string, re.UNICODE)\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    #df_cleaned = df[~df.apply(lambda row: row.astype(str).str.contains(pattern).any(), axis=1)]\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace('\"', ' ')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.strip()\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.rstrip()\n",
    "    #escaped_chars_pattern = re.compile(r'[' + ''.join([re.escape(c) for c in ['\\\\', '\\t', '\\n']]) + ']')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(escaped_chars_pattern, ' ', regex=True)\n",
    "    #excessive_whitespace_pattern = re.compile(r'\\s{2,}')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(excessive_whitespace_pattern, ' ', regex=True)\n",
    "    #df_cleaned.drop([], axis=1, inplace=True)\n",
    "    df_cleanded = df\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def process_and_clean_csv(input_path):\n",
    "    df = pd.read_csv(input_path, header=0, index_col=0, encoding='ISO-8859-1', on_bad_lines='skip')\n",
    "    df_cleaned = clean_dataframe(df)\n",
    "    return df_cleaned\n",
    "\n",
    "### We ultimately decided not to go with uploading a csv to a bucket of our projects. We will instead \n",
    "# feed the df into a bigquery table directly\n",
    "#def upload_file(bucket_name, source_file_path, destination_blob_name):\n",
    "#    bucket = storage_client.bucket(bucket_name)\n",
    "#    blob = bucket.blob(destination_blob_name)\n",
    "#    storage.blob._DEFAULT_CHUNKSIZE = 100 * 1024 * 1024  # 100 MB chunk size\n",
    "#    storage.blob._MAX_MULTIPART_SIZE = 100 * 1024 * 1024  # 100 MB max multipart size\n",
    "#    blob.upload_from_filename(source_file_path, timeout=600)\n",
    "#    print(f'{source_file_path} uploaded to {bucket_name} as {destination_blob_name}.')\n",
    "\n",
    "def load_to_bigquery(df, table_ref):\n",
    "    job = bigquery_client.load_table_from_dataframe(df, table_ref)\n",
    "    job.result()\n",
    "    print(f'Loaded DataFrame into {table_ref.table_id}.')\n",
    "\n",
    "# Service account key\n",
    "key_path = '/Users/chkapsalis/Downloads/nlp-project-427710-3e1a48df3dba.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Google Cloud project id and dataset information\n",
    "project_id = 'nlp-project-427710'\n",
    "dataset_id = 'person_emotion' \n",
    "table_id = 'MBTI_personality' \n",
    "\n",
    "# Initialization of the BigQuery client\n",
    "bigquery_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "\n",
    "# Create the dataset if it does not exist\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "\n",
    "try:\n",
    "    bigquery_client.get_dataset(dataset_ref)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} already exists.\")\n",
    "except:\n",
    "    dataset = bigquery_client.create_dataset(dataset)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} created.\")\n",
    "\n",
    "# Define the job configuration for loading data\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"label\", \"STRING\")\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    field_delimiter='|',  # used this custom delimiter to help make sense out of the data\n",
    "    autodetect=False,  # Automatically detect the schema\n",
    "    max_bad_records=2000,  # Allow up to 2000 bad records\n",
    "    ignore_unknown_values=True  # Ignore unknown values\n",
    ")\n",
    "\n",
    "source_folder = '/Users/chkapsalis/Downloads/person_emotion'\n",
    "cleaned_folder = '/Users/chkapsalis/Downloads/cleaned_person_emotion'\n",
    "\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(source_folder)):\n",
    "    if filename.endswith('.csv'):\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        df_cleaned = pd.read_csv(source_file, header=0, index_col=0, encoding='ISO-8859-1', on_bad_lines='skip')\n",
    "\n",
    "        # making sure that the dtypes of columns match what asserted in the schema\n",
    "        #df_cleaned[''] = pd.to_numeric(df_cleaned['user_followers'], errors='coerce')\n",
    "        table_id = {\n",
    "            'twitter_MBTI.csv': 'MBTI_personality',\n",
    "            #'text.csv': 'emotions1'\n",
    "        }\n",
    "        \n",
    "        # Upload the cleaned DataFrame to BigQuery\n",
    "        #load_to_bigquery(df_cleaned, dataset_ref.table(table_id))\n",
    "        load_to_bigquery(df_cleaned, dataset_ref.table(table_id[filename]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf52082c-a7ac-4db8-bf2d-333f5cb4822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Hispanthicckk Being you makes you look cute||...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alshymi Les balles sont rÃ©elles et sont tirÃ...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm like entp but idiotic|||Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>@sobsjjun God,,pls take care ð|||@sobsjjun ...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>@Ignis_02 wow last time i got intp https://t.c...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>@akupilled A 100%|||@akupilled That SOMEONE wi...</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>If youâre #INTJ this one is for you | What i...</td>\n",
       "      <td>infj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>@harry__lambert @gucci hey can you dm me a pic...</td>\n",
       "      <td>istp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj\n",
       "1     @Hispanthicckk Being you makes you look cute||...  intj\n",
       "2     @Alshymi Les balles sont rÃ©elles et sont tirÃ...  intj\n",
       "3     I'm like entp but idiotic|||Hey boy, do you wa...  intj\n",
       "4     @kaeshurr1 Give it to @ZargarShanif ... He has...  intj\n",
       "...                                                 ...   ...\n",
       "7806  @sobsjjun God,,pls take care ð|||@sobsjjun ...  intp\n",
       "7807  @Ignis_02 wow last time i got intp https://t.c...  intp\n",
       "7808  @akupilled A 100%|||@akupilled That SOMEONE wi...  entp\n",
       "7809  If youâre #INTJ this one is for you | What i...  infj\n",
       "7810  @harry__lambert @gucci hey can you dm me a pic...  istp\n",
       "\n",
       "[7811 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c561b10a-81f4-451a-b99e-f50be5c40449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7811, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aabd73-4834-4351-81da-697664eba9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
