{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chkapsalis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/chkapsalis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isolation', 'mask mandate', 'event', 'epidemic', 'decease', 'dying', 'masquerade', 'messenger RNA', 'end', 'febricity', 'fount', 'symptom', 'Death', 'face', 'distance', 'typeface', 'shortness of breath', 'vaccinum', 'masque', 'pandemic', 'casing', 'case', 'pillowcase', 'last', 'character', 'recuperation', 'Plaquenil', 'informational RNA', 'instance', 'sheath', 'slip', 'showcase', 'convalescence', 'grammatical case', 'COVID-19', 'retrieval', 'causa', 'font', 'eccentric', 'mask', 'death', 'travel ban', 'cough', 'fever', 'cause', 'template RNA', 'hydroxychloroquine', 'closing off', 'lawsuit', 'destruction', 'type', \"compositor's case\", 'feverishness', 'pillow slip', 'vaccine', 'quarantine', 'demise', 'subject', 'shell', 'febrility', 'outdistance', 'lockdown', 'pyrexia', 'recovery', 'guinea pig', 'expiry', 'example', 'caseful', 'mRNA', 'coronavirus', \"typesetter's case\", 'coughing', 'display case', 'masquerade party', 'distancing', 'suit', 'vitrine', 'outstrip'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# List of initial COVID-19 related words\n",
    "covid_related_words = ['COVID-19', 'fever', 'cough', 'shortness of breath', 'coronavirus', 'epidemic', 'pandemic', 'quarantine', 'lockdown', 'vaccine', 'symptom', 'isolation', 'distancing',\n",
    "                    'hydroxychloroquine', 'mRNA', 'mask mandate', 'travel ban', 'mask', 'case', 'death', 'recovery']\n",
    "\n",
    "# Function to find synonyms using WordNet\n",
    "def find_synonyms(word):\n",
    "    synonyms = set()\n",
    "    pos = get_wordnet_pos(pos_tag(word_tokenize(word))[0][-1])\n",
    "    \n",
    "    for syn in wn.synsets(word, pos=pos, lang='eng'):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return synonyms\n",
    "\n",
    "# Expand the list with synonyms\n",
    "expanded_words = set(covid_related_words)\n",
    "for word in covid_related_words:\n",
    "    synonyms = find_synonyms(word)\n",
    "    expanded_words.update(synonyms)\n",
    "\n",
    "# Print the expanded list of COVID-19 related words\n",
    "print(expanded_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "JJ\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "VBG\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import ne_chunk, pos_tag, word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "for word in covid_related_words:\n",
    "    tokens = word_tokenize(word)\n",
    "    print(pos_tag(tokens)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "JJ\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "VBG\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "for word in covid_related_words:\n",
    "    #tokens = word_tokenize(word)\n",
    "    #print(word, pos_tag(word_tokenize(word))[-1])\n",
    "    print(pos_tag(word_tokenize(word))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(['fever'])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
