{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d103ffca-611c-4d16-88a4-9aecc4e153fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset machine_translation already exists.\n"
     ]
    }
   ],
   "source": [
    "from currency_symbols import CurrencySymbols\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Define the regex patterns\n",
    "emoji_pattern = (\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    ")\n",
    "accented_characters = u\"\\u00C0-\\u00FF\"  # Latin-1 Supplement (accented characters)\n",
    "special_symbols = '©®™±≠≤≥∞π∑§¶†•′″‰′′←→↑↓↔↕'\n",
    "\n",
    "# ISO codes for all currencies \n",
    "currencies = [\n",
    "    'AFN', 'EUR', 'ALL', 'DZD', 'USD', 'EUR', 'AOA', 'XCD', 'XCD', 'ARS', 'AMD', 'AWG', 'AUD', 'EUR', 'AZN',\n",
    "    'BSD', 'BHD', 'BDT', 'BBD', 'BYN', 'EUR', 'BZD', 'XOF', 'BMD', 'INR', 'BTN', 'BOB', 'BOV', 'USD', 'BAM',\n",
    "    'BWP', 'NOK', 'BRL', 'USD', 'BND', 'BGN', 'XOF', 'BIF', 'CVE', 'KHR', 'XAF', 'CAD', 'KYD', 'XAF', 'XAF',\n",
    "    'CLP', 'CLF', 'CNY', 'AUD', 'AUD', 'COP', 'COU', 'KMF', 'CDF', 'XAF', 'NZD', 'CRC', 'XOF', 'EUR', 'CUP',\n",
    "    'CUC', 'ANG', 'EUR', 'CZK', 'DKK', 'DJF', 'XCD', 'DOP', 'USD', 'EGP', 'SVC', 'USD', 'XAF', 'ERN', 'EUR',\n",
    "    'SZL', 'ETB', 'EUR', 'FKP', 'DKK', 'FJD', 'EUR', 'EUR', 'EUR', 'XPF', 'EUR', 'XAF', 'GMD', 'GEL', 'EUR',\n",
    "    'GHS', 'GIP', 'EUR', 'DKK', 'XCD', 'EUR', 'USD', 'GTQ', 'GBP', 'GNF', 'XOF', 'GYD', 'HTG', 'USD', 'AUD',\n",
    "    'EUR', 'HNL', 'HKD', 'HUF', 'ISK', 'INR', 'IDR', 'XDR', 'IRR', 'IQD', 'EUR', 'GBP', 'ILS', 'EUR', 'JMD',\n",
    "    'JPY', 'GBP', 'JOD', 'KZT', 'KES', 'AUD', 'KPW', 'KRW', 'KWD', 'KGS', 'LAK', 'EUR', 'LBP', 'LSL', 'ZAR',\n",
    "    'LRD', 'LYD', 'CHF', 'EUR', 'EUR', 'MOP', 'MKD', 'MGA', 'MWK', 'MYR', 'MVR', 'XOF', 'EUR', 'USD', 'EUR',\n",
    "    'MRU', 'MUR', 'EUR', 'XUA', 'MXN', 'MXV', 'USD', 'MDL', 'EUR', 'MNT', 'EUR', 'XCD', 'MAD', 'MZN', 'MMK',\n",
    "    'NAD', 'ZAR', 'AUD', 'NPR', 'EUR', 'XPF', 'NZD', 'NIO', 'XOF', 'NGN', 'NZD', 'AUD', 'USD', 'NOK', 'OMR',\n",
    "    'PKR', 'USD', 'PAB', 'USD', 'PGK', 'PYG', 'PEN', 'PHP', 'NZD', 'PLN', 'EUR', 'USD', 'QAR', 'EUR', 'RON',\n",
    "    'RUB', 'RWF', 'EUR', 'SHP', 'XCD', 'XCD', 'EUR', 'EUR', 'XCD', 'WST', 'EUR', 'STN', 'SAR', 'XOF', 'RSD',\n",
    "    'SCR', 'SLE', 'SGD', 'ANG', 'XSU', 'EUR', 'EUR', 'SBD', 'SOS', 'ZAR', 'SSP', 'EUR', 'LKR', 'SDG', 'SRD',\n",
    "    'NOK', 'SEK', 'CHF', 'CHE', 'CHW', 'SYP', 'TWD', 'TJS', 'TZS', 'THB', 'USD', 'XOF', 'NZD', 'TOP', 'TTD',\n",
    "    'TND', 'TRY', 'TMT', 'USD', 'AUD', 'UGX', 'UAH', 'AED', 'GBP', 'USD', 'USD', 'USN', 'UYU', 'UYI', 'UYW',\n",
    "    'UZS', 'VUV', 'VES', 'VED', 'VND', 'USD', 'USD', 'XPF', 'MAD', 'YER', 'ZMW', 'ZWL', 'ZWG', 'XBA', 'XBB',\n",
    "    'XBC', 'XBD', 'XTS', 'XXX', 'XAU', 'XPD', 'XPT', 'XAG'\n",
    "]\n",
    "\n",
    "currency_symbols = [CurrencySymbols.get_symbol(x) for x in currencies]\n",
    "currency_symbols = [x for x in currency_symbols if x and not x.isalpha()]  # Filter out None values and alphabetic characters\n",
    "\n",
    "pattern_string = (\n",
    "    r'[^a-zA-Z0-9\\s' +\n",
    "    ''.join([re.escape(x) for x in string.punctuation]) +\n",
    "    ''.join([re.escape(x) for x in currency_symbols]) +\n",
    "    special_symbols +\n",
    "    emoji_pattern +\n",
    "    accented_characters +\n",
    "    ']'\n",
    ")\n",
    "\n",
    "pattern = re.compile(pattern_string, re.UNICODE)\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    #df_cleaned = df[~df.apply(lambda row: row.astype(str).str.contains(pattern).any(), axis=1)]\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace('\"', ' ')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.strip()\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.rstrip()\n",
    "    #escaped_chars_pattern = re.compile(r'[' + ''.join([re.escape(c) for c in ['\\\\', '\\t', '\\n']]) + ']')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(escaped_chars_pattern, ' ', regex=True)\n",
    "    #excessive_whitespace_pattern = re.compile(r'\\s{2,}')\n",
    "    #df_cleaned['text'] = df_cleaned['text'].str.replace(excessive_whitespace_pattern, ' ', regex=True)\n",
    "    #df_cleaned.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "    df_cleaned = df\n",
    "    # Convert BoW column from list to string\n",
    "    df_cleaned['BoW'] = df_cleaned['BoW'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "    ### later when i load this table as a df in google colab\n",
    "    ### Convert 'BoW' column to ndarray\n",
    "    ###df['BoW'] = df['BoW'].apply(lambda x: x.split())  # Split by space to get list of words\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def process_and_clean_csv(input_path):\n",
    "    df = pd.read_csv(input_path, header=0, index_col=False, sep=',', encoding='utf-8', on_bad_lines='skip')\n",
    "    df_cleaned = clean_dataframe(df)\n",
    "    return df_cleaned\n",
    "\n",
    "def load_to_bigquery(df, table_ref):\n",
    "    job = bigquery_client.load_table_from_dataframe(df, table_ref)\n",
    "    job.result()\n",
    "    print(f'Loaded DataFrame into {table_ref.table_id}.')\n",
    "\n",
    "# Service account key\n",
    "key_path = '/Users/chkapsalis/Downloads/nlp-project-427710-3e1a48df3dba.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Google Cloud project id and dataset information\n",
    "project_id = 'nlp-project-427710'\n",
    "dataset_id = 'machine_translation'  # Replace with your dataset ID\n",
    "table_id = 'wmt2014'  # Replace with your table ID\n",
    "\n",
    "# Initialization of the BigQuery client\n",
    "bigquery_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "\n",
    "# Create the dataset if it does not exist\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "\n",
    "try:\n",
    "    bigquery_client.get_dataset(dataset_ref)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} already exists.\")\n",
    "except:\n",
    "    dataset = bigquery_client.create_dataset(dataset)  # Make an API request.\n",
    "    print(f\"Dataset {dataset_id} created.\")\n",
    "\n",
    "# Define the job configuration for loading data\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"userid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"user_reported_location\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"user_profile_description\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"follower_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"BoW\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"retweet_ratio\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"english_tweet_proportion\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"earliest_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"latest_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"average_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"median_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"tweet_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"stddev_tweet_time\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_0\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_1\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_2\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_3\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_4\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_5\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_6\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_7\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_8\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_9\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_10\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_11\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_12\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_13\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_14\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_15\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_16\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_17\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_18\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_19\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_20\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_21\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_22\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"mode_23\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_week\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_day\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_hour\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_tweets_per_min\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_quote_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_like_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_retweet_count\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_hashtags\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_urls\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"avg_user_mentions\", \"DECIMAL\"),\n",
    "        bigquery.SchemaField(\"info_op\", \"INTEGER\")\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    field_delimiter='|',  # used this custom delimiter to help make sense out of the data\n",
    "    autodetect=False,  # Automatically detect the schema\n",
    "    max_bad_records=2000,  # Allow up to 2000 bad records\n",
    "    ignore_unknown_values=True  # Ignore unknown values\n",
    ")\n",
    "\n",
    "source_folder = '/Users/chkapsalis/Downloads/machine_translation'\n",
    "filename = 'wmt14_translate_de-en_train.csv'\n",
    "source_file = os.path.join(source_folder, filename)\n",
    "# making sure that the dtypes of columns match what asserted in the schema\n",
    "#for col in df_cleaned.columns.difference(['userid','BoW']):\n",
    "#    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "        \n",
    "# Upload the cleaned DataFrame to BigQuery\n",
    "#load_to_bigquery(df_cleaned, dataset_ref.table(table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1aa394-0260-45e2-9ba8-ea6916054ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579762b-a943-444a-824b-7dc1793678c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78b9ed-0420-4521-a23d-ca238d1b6b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5b36a0-3480-4427-bc3f-18ad6e316194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chkapsalis/Downloads/machine_translation/wmt14_translate_de-en_train.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1280cc46-eb6a-47ae-8745-43cb68edb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        de  \\\n",
      "0                                                       de   \n",
      "1        An der B 211 befindet sich in Loyermoor der so...   \n",
      "2        Ich begrüße die Erklärung des Herrn Kommissar ...   \n",
      "3        Das ist das Gegenteil von dem, was getan werde...   \n",
      "4                                                        .   \n",
      "...                                                    ...   \n",
      "4508781  Die Kommission hat im Rahmen einer fischereisp...   \n",
      "4508782  Zudem müssen die derzeitigen Finanzverordnunge...   \n",
      "4508783  Unsere zentrale Lage im Lido, ermöglicht die F...   \n",
      "4508784  schriftlich. - (FR) Ich habe für diesen Berich...   \n",
      "4508785  Den extra Komfort finden Sie in einem geräumig...   \n",
      "\n",
      "                                                        en  \n",
      "0                                                       en  \n",
      "1        Here the largest town of the district is locat...  \n",
      "2        I should like, in passing, to pay tribute to t...  \n",
      "3        That is the opposite of what should be done an...  \n",
      "4                                                        .  \n",
      "...                                                    ...  \n",
      "4508781  The Commission has established a constant dial...  \n",
      "4508782  The current financial regulations, which expre...  \n",
      "4508783  Our strategic position and the direct links wi...  \n",
      "4508784  in writing. - (FR) I voted for this report by ...  \n",
      "4508785  The extra comfort is in the large living space...  \n",
      "\n",
      "[4508786 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "cleaned_file_path = '/Users/chkapsalis/Downloads/machine_translation/cleaned.csv'\n",
    "\n",
    "# We faced difficulties direcly reading the file to pandas. So we will follow an indirect approach:\n",
    "# First we read the file line by line and clean it\n",
    "with open(file_path, 'r', encoding='utf-8') as infile, open(cleaned_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # writing the header of the df\n",
    "    writer.writerow([\"de\", \"en\"])\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # Ensure there are exactly 2 columns in case that was the issue we had\n",
    "            if len(row) == 2:\n",
    "                writer.writerow(row)\n",
    "        except csv.Error as e:\n",
    "            print(f'Error parsing line: {row}, error: {e}')\n",
    "\n",
    "# Then we may abruptly load the cleaned CSV into pandas DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(cleaned_file_path, encoding='utf-8', quotechar='\"', delimiter=',')\n",
    "    print(df)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(\"Error parsing cleaned file:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17144fc9-23bb-4009-b29d-1701faa1307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cleaned_file_path)\n",
    "# I will contain less than 5 characters in either 'de' or 'en':\n",
    "\n",
    "df.dropna(subset=['de', 'en'], inplace=True)  # drop upon coming across a missing value in either column\n",
    "\n",
    "# convert all values to strings to prevent any string method-related errors\n",
    "df['de'] = df['de'].astype(str)\n",
    "df['en'] = df['en'].astype(str)\n",
    "\n",
    "df = df[df['de'].apply(len) >= 5]\n",
    "df = df[df['en'].apply(len) >= 5]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79afb961-0077-4d6b-8c90-9df498565bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3758551</th>\n",
       "      <td>Dokumente, die erst in einer Arbeitsfassung vo...</td>\n",
       "      <td>Documents that are only in the draft stage are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196917</th>\n",
       "      <td>Nachfolgend sehen Sie die Gästebewertungen von...</td>\n",
       "      <td>The guest reviews are submitted by our custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497539</th>\n",
       "      <td>The apartment is advertised as 2 bedroom but t...</td>\n",
       "      <td>Er zat een kakkerlak in één van de badkamers! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329406</th>\n",
       "      <td>Zunächst eine Definition des Geltungsbereichs ...</td>\n",
       "      <td>Firstly, a definition of the scope of the dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461769</th>\n",
       "      <td>Mit DFX Audio Enhancer for Winamp werden alle ...</td>\n",
       "      <td>DFX Audio Enhancer for Windows Media Player el...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        de  \\\n",
       "3758551  Dokumente, die erst in einer Arbeitsfassung vo...   \n",
       "3196917  Nachfolgend sehen Sie die Gästebewertungen von...   \n",
       "2497539  The apartment is advertised as 2 bedroom but t...   \n",
       "1329406  Zunächst eine Definition des Geltungsbereichs ...   \n",
       "3461769  Mit DFX Audio Enhancer for Winamp werden alle ...   \n",
       "\n",
       "                                                        en  \n",
       "3758551  Documents that are only in the draft stage are...  \n",
       "3196917  The guest reviews are submitted by our custome...  \n",
       "2497539  Er zat een kakkerlak in één van de badkamers! ...  \n",
       "1329406  Firstly, a definition of the scope of the dire...  \n",
       "3461769  DFX Audio Enhancer for Windows Media Player el...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=1000000, random_state=11)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b083f399-344a-49be-9b4a-bd68d0cfdb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SANITY CHECK\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c24918-4939-4d97-b8b3-05d478f3b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_bigquery(df, dataset_ref.table(table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e8209-8ba6-4676-8685-2913d4f557ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
